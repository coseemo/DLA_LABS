#Esperimento 1.1: MLP con MNIST
seed: 42 

data:
  batch_size: 128
  validation_split: 20  #Percentuale che definisce la grandezza del validation set
  num_workers: 4

model:
  type: "MLP"
  params:
    input_size: 784 #28*28 per MNIST
    layers_dim: 32 #64 #128
    class_num: 10
    hidden_layers_num: 10 #20 #40
    residual: false
    activation: "ReLU"
    dropout: 0.0
    batch_norm: true

training:
  epochs: 50 
  criterion: "CrossEntropyLoss"
  optimizer: "Adam"
  lr: 0.001
  scheduler: "CosineAnnealingLR"

logging:
  project_name: "LAB1-CNN"
  log_gradients: false